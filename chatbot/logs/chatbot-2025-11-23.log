{"ts":"2025-11-23T18:17:34.702Z","level":"INFO","msg":"Chatbot läuft auf http://localhost:3100 (GUI: /gui)","extra":null}
{"ts":"2025-11-23T18:18:06.768Z","level":"DEBUG","msg":"EINFO-Inputs gelesen","extra":{"scenarioConfigPresent":true,"stabMessagesCount":3,"lageInputsCount":0}}
{"ts":"2025-11-23T18:18:06.769Z","level":"INFO","msg":"Simulation gestartet","extra":{"scenarioId":"hochwasser_feldkirchen_01"}}
{"ts":"2025-11-23T18:20:30.878Z","level":"DEBUG","msg":"EINFO-Inputs gelesen","extra":{"scenarioConfigPresent":true,"stabMessagesCount":3,"lageInputsCount":0}}
{"ts":"2025-11-23T18:20:30.897Z","level":"DEBUG","msg":"LLM-Request wird gesendet","extra":{"model":"phi3_cpu"}}
{"ts":"2025-11-23T18:20:32.562Z","level":"ERROR","msg":"LLM-HTTP-Fehler","extra":{"status":500,"statusText":"Internal Server Error","body":"{\"error\":\"model requires more system memory than is currently available unable to load full model on GPU\"}"}}
{"ts":"2025-11-23T18:20:32.563Z","level":"ERROR","msg":"Fehler im Simulationsschritt","extra":{"error":"Error: LLM error: 500 Internal Server Error"}}
{"ts":"2025-11-23T18:41:10.549Z","level":"INFO","msg":"Chatbot läuft auf http://localhost:3100 (GUI: /gui)","extra":null}
{"ts":"2025-11-23T18:43:02.859Z","level":"DEBUG","msg":"EINFO-Inputs gelesen","extra":{"scenarioConfigPresent":true,"stabMessagesCount":3,"lageInputsCount":0}}
{"ts":"2025-11-23T18:43:02.860Z","level":"INFO","msg":"Simulation gestartet","extra":{"scenarioId":"hochwasser_feldkirchen_01"}}
{"ts":"2025-11-23T18:43:08.611Z","level":"DEBUG","msg":"EINFO-Inputs gelesen","extra":{"scenarioConfigPresent":true,"stabMessagesCount":3,"lageInputsCount":0}}
{"ts":"2025-11-23T18:43:08.617Z","level":"DEBUG","msg":"LLM-Request wird gesendet","extra":{"model":"phi3_cpu"}}
